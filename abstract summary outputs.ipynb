{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Mon Apr 30 18:46:02 2019\n",
    "\n",
    "@author: Bhumika_Patoliya\n",
    "\"\"\"\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_article(file_name):\n",
    "    #file_name =\"text.txt\"\n",
    "    file = open(file_name, \"r\")\n",
    "    sentences = []\n",
    "    article =[]\n",
    "    i =0\n",
    "\n",
    "    filedata = file.readlines()\n",
    "    for i in range(len(filedata)):\n",
    "        art = filedata[i].split(\". \")\n",
    "        article = article + art\n",
    "\n",
    "    for sentence in article:\n",
    "        #print(sentence)\n",
    "        sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))\n",
    "    sentences.pop() \n",
    "    \n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity(sent1, sent2, stopwords=None):\n",
    "    if stopwords is None:\n",
    "        stopwords = []\n",
    " \n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    " \n",
    "    all_words = list(set(sent1 + sent2))\n",
    " \n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    " \n",
    "    # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector1[all_words.index(w)] += 1\n",
    " \n",
    "    # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector2[all_words.index(w)] += 1\n",
    " \n",
    "    return 1 - cosine_distance(vector1, vector2)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_similarity_matrix(sentences, stop_words):\n",
    "    # Create an empty similarity matrix\n",
    "    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    " \n",
    "    for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "            if idx1 == idx2: #ignore if both are same sentences\n",
    "                continue \n",
    "            similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stop_words)\n",
    "\n",
    "    return similarity_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(file_name, top_n=5):\n",
    "    #nltk.download(\"stopwords\")\n",
    "    stop_words = stopwords.words('english')\n",
    "    summarize_text = []\n",
    "\n",
    "    # Step 1 - Read text anc split it\n",
    "    sentences =  read_article(file_name)\n",
    "\n",
    "    # Step 2 - Generate Similary Martix across sentences\n",
    "    sentence_similarity_martix = build_similarity_matrix(sentences, stop_words)\n",
    "    print(\"Similarity Matrix:\\n\", sentence_similarity_martix)\n",
    "    \n",
    "    # Step 3 - Rank sentences in similarity martix\n",
    "    sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_martix)\n",
    "    scores = nx.pagerank(sentence_similarity_graph)\n",
    "\n",
    "    # Step 4 - Sort the rank and pick top sentences\n",
    "    ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
    "    #print(\"Indexes of top ranked_sentence order are \", ranked_sentence)    \n",
    "\n",
    "    for i in range(top_n):\n",
    "      summarize_text.append(\" \".join(ranked_sentence[i][1]))\n",
    "\n",
    "    # Step 5 - Offcourse, output the summarize texr\n",
    "    print(\"Summary Text: \\n\", \". \".join([x.strip() for x in summarize_text]) + \".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Matrix:\n",
      " [[0.         0.988399   0.99016367 ... 0.96159993 0.97317527 0.98222029]\n",
      " [0.988399   0.         0.98727843 ... 0.9545366  0.96844804 0.9793582 ]\n",
      " [0.99016367 0.98727843 0.         ... 0.95624081 0.97017708 0.98110673]\n",
      " ...\n",
      " [0.96159993 0.9545366  0.95624081 ... 0.         0.9380024  0.94856957]\n",
      " [0.97317527 0.96844804 0.97017708 ... 0.9380024  0.         0.96239405]\n",
      " [0.98222029 0.9793582  0.98110673 ... 0.94856957 0.96239405 0.        ]]\n",
      "\n\nSummary Text: \n",
      "I  did  not  feel  rushed  one  bit  which  is  nice  because  I  have  visited  an  urgent  care  before  and  I  was  in  and  out  so  quickly  and  left  in  pain  exactly  as  I  was  before  with  no  explanation  for  why.I  definitely  recommend  this  office  for  anyone  in  need  of  health  services  and  wonderful  patient  services. Definitely  one  of  the  best  urgent  care  experiences  I've  had."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    generate_summary( \"text_pos.txt\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Matrix:\n",
      " [[0.         0.91520863 0.93665413 ... 0.94803414 0.         0.96088998]\n",
      " [0.91520863 0.         0.90971765 ... 0.92077039 0.23570226 0.93325653]\n",
      " [0.93665413 0.90971765 0.         ... 0.94234621 0.         0.95905548]\n",
      " ...\n",
      " [0.94803414 0.92077039 0.94234621 ... 0.         0.         0.96672935]\n",
      " [0.         0.23570226 0.         ... 0.         0.         0.        ]\n",
      " [0.96088998 0.93325653 0.95905548 ... 0.96672935 0.         0.        ]]\n",
      "\n\nSummary Text: \n",
      "I  don't  do  that. About  a  month  later  I  receive  a  bill  in  the  mail  stating  that  I  never  paid  the  copay,  and  also  charging  me  an  additional  $35  for  a  referral  Dr  Lee  had  given  to  me,  which  I  did  not  even  ask  for! I  called  Ara  and  the  women  i  spoke  to  (who  was  very  unprofessional  btw)  said  there  is  nothing  they  can  do  and  they  will  not  remove  that  charge  from  the  invoice."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    generate_summary( \"text_neg.txt\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Matrix:\n",
      " [[0.         0.95923051 0.96723882 ... 0.96776208 0.95694875 0.97207427]\n",
      " [0.95923051 0.         0.95694267 ... 0.95746035 0.94676214 0.96172665]\n",
      " [0.96723882 0.95694267 0.         ... 0.97349933 0.9626219  0.97783709]\n",
      " ...\n",
      " [0.96776208 0.95746035 0.97349933 ... 0.         0.96314266 0.98040434]\n",
      " [0.95694875 0.94676214 0.9626219  ... 0.96314266 0.         0.96743427]\n",
      " [0.97207427 0.96172665 0.97783709 ... 0.98040434 0.96743427 0.        ]]\n",
      "\n\nSummary Text: \n",
      "Finally,  the  doctor  came  in,  he  didn't  seem  he  had  a  clue  and  didn't  bother  to  read  any  of  the  details  in  my  chart  (which  doesn't  actually  have  much  on  there,  it  would  have  take  him  maybe  5  mins  to  look  over...)  He  rushed  me  out  in  a  mere  2  minutes,  did  not  answer  any  questions  even  though  I  wanted  to  get  some  information  on  getting  pregnant  (kind  of  important  for  someone  that  wants  to  become  a  1st-time  mommy)  I  left  with  nothing  but  anger. Always  open  for  appointments  ...excellent  services...dr  I  Baker  is  the  best  and  the  staff  are  very  friendly."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    generate_summary( \"text_neu.txt\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
